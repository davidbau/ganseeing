{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, copy\n",
    "from ganpaint import nethook, setting, show, renormalize, zdataset, pbar\n",
    "from ganpaint.encoder_loss import cor_square_error\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "unwrapped_G = setting.load_proggan('church').cuda()\n",
    "zds = zdataset.z_sample_for_model(unwrapped_G).cuda()\n",
    "gt = {}\n",
    "gt['z'] = zds[10:11]\n",
    "\n",
    "with nethook.InstrumentedModel(unwrapped_G) as inst_G:\n",
    "    inst_G.retain_layers(['layer1', 'layer2', 'layer3', 'layer4'])\n",
    "    target_x = inst_G(gt['z'])\n",
    "    for n, v in inst_G.retained_features().items():\n",
    "        gt[n] = v\n",
    "    gt['x'] = target_x\n",
    "show([[renormalize.as_image(gt['x'][0])],\n",
    "      [(n, 'shape') + tuple(d.shape) for n, d in gt.items()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganpaint import encoder_net, nethook\n",
    "\n",
    "E = nethook.InstrumentedModel(encoder_net.HybridLayerNormEncoder())\n",
    "filename = 'results/church/invert_hybrid_cse/snapshots/epoch_1000.pth.tar'\n",
    "E.load_state_dict(torch.load(filename)['state_dict'])\n",
    "E.eval().cuda()\n",
    "E1 = E\n",
    "\n",
    "E = encoder_net.HybridLayerNormEncoder()\n",
    "filename = 'results/church/invert_hybrid_bottom_b5/snapshots/epoch_1000.pth.tar'\n",
    "E.load_state_dict(torch.load(filename)['state_dict'])\n",
    "E.eval().cuda()\n",
    "E2 = E\n",
    "\n",
    "init_z = E(target_x)\n",
    "renormalize.as_image(unwrapped_G(init_z)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = encoder_net.make_over5_resnet()\n",
    "filename = 'results/church/invert_over5_resnet/snapshots/epoch_100.pth.tar'\n",
    "F.load_state_dict(torch.load(filename)['state_dict'])\n",
    "F.eval().cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R4 = nethook.subsequence(encoder_net.HybridLayerNormEncoder(), first_layer='inv4')\n",
    "filename = 'results/church/invert_hybrid_bottom_b4/snapshots/epoch_1000.pth.tar'\n",
    "R4.load_state_dict(torch.load(filename)['state_dict'])\n",
    "R4.eval().cuda()\n",
    "\n",
    "R3 = nethook.subsequence(encoder_net.HybridLayerNormEncoder(), first_layer='inv3')\n",
    "filename = 'results/church/invert_hybrid_bottom_b3/snapshots/epoch_1000.pth.tar'\n",
    "R3.load_state_dict(torch.load(filename)['state_dict'])\n",
    "R3.eval().cuda()\n",
    "\n",
    "R2 = nethook.subsequence(encoder_net.HybridLayerNormEncoder(), first_layer='inv2')\n",
    "filename = 'results/church/invert_hybrid_bottom_b2/snapshots/epoch_1000.pth.tar'\n",
    "R2.load_state_dict(torch.load(filename)['state_dict'])\n",
    "R2.eval().cuda()\n",
    "\n",
    "R1 = nethook.subsequence(encoder_net.HybridLayerNormEncoder(), first_layer='inv1')\n",
    "filename = 'results/church/invert_hybrid_bottom_b1/snapshots/epoch_1000.pth.tar'\n",
    "R1.load_state_dict(torch.load(filename)['state_dict'])\n",
    "R1.eval().cuda()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganpaint.LBFGS import FullBatchLBFGS\n",
    "\n",
    "def estimate_z(G, gt):\n",
    "    cur = G.retained_features()\n",
    "    for i in range(1, 4+1):\n",
    "        if hasattr(G, 'd%d' % i):\n",
    "            cur['layer%d' % i] = cur['layer%d' % i] + getattr(G, 'd%d' % i)\n",
    "    cur['z'] = G.init_z\n",
    "    if hasattr(G, 'dz'):\n",
    "        cur['z'] = cur['z'] + G.dz\n",
    "    else:\n",
    "        cur['z'] = (R1(cur['layer1']) +\n",
    "                    R2(cur['layer2']) +\n",
    "                    R3(cur['layer3']) +\n",
    "                    R4(cur['layer4'])) / 4\n",
    "    err = {} if gt is None else {n: cor_square_error(gt[n], c) for n, c in cur.items()}\n",
    "    return cur['z'], err\n",
    "\n",
    "def refine_z(init_z, target_x, gt, optimize_over=None,\n",
    "             lr=0.02, lambda_f=0.25, num_steps=3000, show_every=100):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if optimize_over is None:\n",
    "        optimize_over = ['layer1']\n",
    "    show.flush()\n",
    "    G = encoder_net.ResidualGenerator(copy.deepcopy(unwrapped_G), init_z, optimize_over)\n",
    "    G.retain_layers(['layer1', 'layer2', 'layer3', 'layer4'])\n",
    "\n",
    "    parameters = list(G.parameters(recurse=False))\n",
    "    nethook.set_requires_grad(False, G, E)\n",
    "    nethook.set_requires_grad(True, *parameters)\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        target_f = F(target_x)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for step_num in pbar(range(num_steps + 1)):\n",
    "            current_x = G()\n",
    "            loss_x = l1_loss(target_x, current_x)\n",
    "            loss_f = mse_loss(target_f, F(current_x))\n",
    "            loss = loss_x + loss_f * lambda_f\n",
    "            if show_every and step_num % show_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    est_z, err = estimate_z(G, gt)\n",
    "                    show.a(\n",
    "                        ['step %d' % step_num] +\n",
    "                        ['loss: %f' % loss.item()] +\n",
    "                        ['loss_x: %f' % loss_x.item()] +\n",
    "                        ['loss_f: %f' % loss_f.item()] +\n",
    "                        ['err in %s: %f' % (n, e) for n, e in err.items()] +\n",
    "                        [[renormalize.as_image(current_x[0])]], cols=3)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if step_num > 0:\n",
    "                optimizer.step()\n",
    "        show.flush()\n",
    "    est_z, err = estimate_z(G, gt)\n",
    "    return est_z, err\n",
    "\n",
    "def refine_z_lbfgs(init_z, target_x, gt, optimize_over=None, lambda_f=0.25,\n",
    "                   num_steps=1000, show_every=100):\n",
    "\n",
    "    if optimize_over is None:\n",
    "        optimize_over = ['layer1']\n",
    "    show.flush()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_f = F(target_x)\n",
    "\n",
    "    G = encoder_net.ResidualGenerator(copy.deepcopy(unwrapped_G), init_z, optimize_over)\n",
    "    G.retain_layers(['layer1', 'layer2', 'layer3', 'layer4', ('output_256x256', 'x')])\n",
    "\n",
    "    parameters = list(G.parameters(recurse=False))\n",
    "    nethook.set_requires_grad(False, G, E)\n",
    "    nethook.set_requires_grad(True, *parameters)\n",
    "    optimizer = FullBatchLBFGS(parameters)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        current_x = G()\n",
    "        loss = l1_loss(target_x, current_x)\n",
    "        if lambda_f:\n",
    "            loss += mse_loss(target_f, F(current_x)) * lambda_f\n",
    "        return loss\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for step_num in pbar(range(num_steps + 1)):\n",
    "            if step_num == 0:\n",
    "                loss = closure()\n",
    "                loss.backward()\n",
    "                lr, F_eval, G_eval = 0, 0, 0\n",
    "            else:\n",
    "                options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "                loss, _, lr, _, _, _, _, _ = optimizer.step(options)\n",
    "            if step_num % show_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    est_z, err = estimate_z(G, gt)\n",
    "                    show.a(\n",
    "                        ['step %d' % step_num] +\n",
    "                        ['loss: %f' % loss.item()] +\n",
    "                        ['lr: %f' % lr] +\n",
    "                        ['err in %s: %f' % (n, e) for n, e in err.items()] +\n",
    "                        [[renormalize.as_image(G.retained_layer('x')[0])]], cols=3)\n",
    "        if show_every > 0:\n",
    "            show.flush()\n",
    "    est_z, err = estimate_z(G, gt)\n",
    "    return est_z, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"Phase 1\")\n",
    "    new_z_1, _ = refine_z(init_z,  target_x, gt, optimize_over=['layer1'], num_steps=5000, show_every=1000)\n",
    "    print(\"Phase 2\")\n",
    "    new_z_2, _ = refine_z(new_z_1, target_x, gt, optimize_over=['layer1'], num_steps=2000, show_every=1000)\n",
    "    print(\"Phase 3\")\n",
    "    new_z_3, _ = refine_z(new_z_2, target_x, gt, optimize_over=['z'], num_steps=10000, show_every=1000)\n",
    "    print(\"Phase 4\")\n",
    "    new_z_4, _ = refine_z(new_z_3, target_x, gt, optimize_over=['z'], lambda_f=0.5, num_steps=10000, show_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_gt(true_z):\n",
    "    gt = dict(z=true_z)\n",
    "    with nethook.InstrumentedModel(unwrapped_G) as inst_G:\n",
    "        inst_G.retain_layers(['layer1', 'layer2', 'layer3', 'layer4'])\n",
    "        target_x = inst_G(gt['z'])\n",
    "        for n, v in inst_G.retained_features().items():\n",
    "            gt[n] = v\n",
    "        gt['x'] = target_x\n",
    "    return gt\n",
    "\n",
    "def test_image(true_z):\n",
    "    gt = get_gt(true_z)\n",
    "    target_x = gt['x']\n",
    "    init_z = E(target_x)\n",
    "    new_z, err = refine_z_lbfgs(init_z, target_x, gt, optimize_over=['z'], num_steps=5000, show_every=1000)\n",
    "    est = get_gt(new_z)\n",
    "    return new_z, gt, est\n",
    "\n",
    "all_gt, all_est = defaultdict(list), defaultdict(list)\n",
    "for n in pbar(range(10)):\n",
    "    _, gt, est = test_image(zds[n][None,...])\n",
    "    for k in gt:\n",
    "        all_gt[k].append(gt[k].view(-1).cpu().numpy())\n",
    "        all_est[k].append(est[k].view(-1).cpu().numpy())\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy, matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9,7), dpi=100)\n",
    "for i, k in enumerate(all_gt.keys()):\n",
    "    gtcat = numpy.concatenate(all_gt[k])\n",
    "    estcat = numpy.concatenate(all_est[k])\n",
    "    if k == 'z':\n",
    "        estcat /= numpy.e\n",
    "    ax = axes[i % 2, i // 2]\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(gtcat, estcat, alpha=0.5, s=0.5)\n",
    "    ax.set_title('%s: corr %.5f' % (k, numpy.corrcoef(gtcat, estcat)[0,1]))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People: 120, 407, 441, 447, 457, 463, 515, 520, 523, 569, 571, 594, 639, 646, 751, 787, 874, 882, 883, 895, 906, 911\n",
    "# Buildings: 90\n",
    "# Fence: 767\n",
    "# Busy street: 638\n",
    "# Text: 469, 503\n",
    "# Monument: 477, 485\n",
    "real_x = setting.load_image('church', 485)[None,...].cuda()\n",
    "\n",
    "renormalize.as_image(real_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [90, 120, 407, 441, 447, 457, 463, 515, 520, 523, 569, 571, 594, 639, 646, 751, 787, 874, 882, 883, 895, 906, 911]:\n",
    "    real_x = setting.load_image('church', i)[None,...].cuda()\n",
    "    renormalize.as_image(real_x[0])\n",
    "    init_z = E2(real_x)\n",
    "    show.a([renormalize.as_image(real_x[0])])\n",
    "    new_z, err = refine_z_lbfgs(init_z, real_x, None, optimize_over=['z'], lambda_f=0.25, num_steps=5000, show_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [90, 120, 407, 441, 447, 457, 463, 515, 520, 523, 569, 571, 594, 639, 646, 751, 787, 874, 882, 883, 895, 906, 911]:\n",
    "    real_x = setting.load_image('church', i)[None,...].cuda()\n",
    "    renormalize.as_image(real_x[0])\n",
    "    init_z = E1(real_x)\n",
    "    show.a([renormalize.as_image(real_x[0])])\n",
    "    new_z, err = refine_z_lbfgs(init_z, real_x, None, optimize_over=['z'], lambda_f=0.25, num_steps=5000, show_every=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}